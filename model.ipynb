{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import gradio as gr\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.regularizers import l2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  to split the data of training and testing sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
    "input_shape = (28, 28, 1)\n",
    "# conversion of class vectors to matrices of  binary class \n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 20  # Increased number of epochs for better training\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))  # Added an additional convolutional layer\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, kernel_regularizer=l2(0.001), activation='relu'))  # Added L2 regularization\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adam(),metrics=['accuracy'])  # Changed optimizer to Adam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_5 (Conv2D)           (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 24, 24, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 12, 12, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 12, 12, 64)        0         \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 10, 10, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 5, 5, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 5, 5, 128)         0         \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 3200)              0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 256)               819456    \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 10)                2570      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 914,698\n",
      "Trainable params: 914,698\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "469/469 [==============================] - 103s 219ms/step - loss: 0.4213 - accuracy: 0.9302 - val_loss: 0.1651 - val_accuracy: 0.9853\n",
      "Epoch 2/20\n",
      "469/469 [==============================] - 100s 213ms/step - loss: 0.1781 - accuracy: 0.9763 - val_loss: 0.1228 - val_accuracy: 0.9897\n",
      "Epoch 3/20\n",
      "469/469 [==============================] - 93s 199ms/step - loss: 0.1517 - accuracy: 0.9797 - val_loss: 0.1140 - val_accuracy: 0.9894\n",
      "Epoch 4/20\n",
      "469/469 [==============================] - 98s 209ms/step - loss: 0.1411 - accuracy: 0.9821 - val_loss: 0.1095 - val_accuracy: 0.9905\n",
      "Epoch 5/20\n",
      "469/469 [==============================] - 89s 190ms/step - loss: 0.1342 - accuracy: 0.9829 - val_loss: 0.1115 - val_accuracy: 0.9889\n",
      "Epoch 6/20\n",
      "469/469 [==============================] - 90s 192ms/step - loss: 0.1294 - accuracy: 0.9840 - val_loss: 0.0997 - val_accuracy: 0.9927\n",
      "Epoch 7/20\n",
      "469/469 [==============================] - 85s 180ms/step - loss: 0.1268 - accuracy: 0.9845 - val_loss: 0.1011 - val_accuracy: 0.9925\n",
      "Epoch 8/20\n",
      "469/469 [==============================] - 85s 182ms/step - loss: 0.1268 - accuracy: 0.9856 - val_loss: 0.1066 - val_accuracy: 0.9926\n",
      "Epoch 9/20\n",
      "469/469 [==============================] - 86s 183ms/step - loss: 0.1209 - accuracy: 0.9862 - val_loss: 0.1007 - val_accuracy: 0.9923\n",
      "Epoch 10/20\n",
      "469/469 [==============================] - 84s 180ms/step - loss: 0.1200 - accuracy: 0.9860 - val_loss: 0.1047 - val_accuracy: 0.9918\n",
      "Epoch 11/20\n",
      "469/469 [==============================] - 85s 181ms/step - loss: 0.1224 - accuracy: 0.9866 - val_loss: 0.0978 - val_accuracy: 0.9937\n",
      "Epoch 12/20\n",
      "469/469 [==============================] - 84s 180ms/step - loss: 0.1142 - accuracy: 0.9876 - val_loss: 0.0955 - val_accuracy: 0.9943\n",
      "Epoch 13/20\n",
      "469/469 [==============================] - 83s 178ms/step - loss: 0.1138 - accuracy: 0.9881 - val_loss: 0.0956 - val_accuracy: 0.9932\n",
      "Epoch 14/20\n",
      "469/469 [==============================] - 85s 181ms/step - loss: 0.1117 - accuracy: 0.9880 - val_loss: 0.0975 - val_accuracy: 0.9941\n",
      "Epoch 15/20\n",
      "469/469 [==============================] - 84s 180ms/step - loss: 0.1156 - accuracy: 0.9877 - val_loss: 0.0948 - val_accuracy: 0.9934\n",
      "Epoch 16/20\n",
      "469/469 [==============================] - 85s 181ms/step - loss: 0.1126 - accuracy: 0.9880 - val_loss: 0.0929 - val_accuracy: 0.9940\n",
      "Epoch 17/20\n",
      "469/469 [==============================] - 85s 182ms/step - loss: 0.1054 - accuracy: 0.9893 - val_loss: 0.0912 - val_accuracy: 0.9940\n",
      "Epoch 18/20\n",
      "469/469 [==============================] - 84s 180ms/step - loss: 0.1117 - accuracy: 0.9883 - val_loss: 0.0949 - val_accuracy: 0.9940\n",
      "Epoch 19/20\n",
      "469/469 [==============================] - 84s 180ms/step - loss: 0.1090 - accuracy: 0.9889 - val_loss: 0.0941 - val_accuracy: 0.9936\n",
      "Epoch 20/20\n",
      "469/469 [==============================] - 85s 181ms/step - loss: 0.1063 - accuracy: 0.9892 - val_loss: 0.0906 - val_accuracy: 0.9940\n",
      "The model has successfully trained\n",
      "Saving the bot as mnist.h5\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train,batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(x_test, y_test))\n",
    "print(\"The model has successfully trained\")\n",
    "model.save('mnist.h5')\n",
    "print(\"Saving the bot as mnist.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.09064210951328278\n",
      "Test accuracy: 0.9940000176429749\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7880\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7880/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 101ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Load the trained MNIST model\n",
    "model = tf.keras.models.load_model('mnist.h5')\n",
    "\n",
    "# Define a function to preprocess the input sketchpad image\n",
    "def preprocess_image(image):\n",
    "    \n",
    "    image = Image.fromarray(np.uint8(image))\n",
    "    # Convert the image to grayscale\n",
    "    image = image.convert('L')\n",
    "    # Resize the image to 28x28 pixels (MNIST image size)\n",
    "    image = image.resize((28, 28))\n",
    "    # Convert the image to a NumPy array\n",
    "    image = np.array(image)\n",
    "    # Normalize the image pixel values\n",
    "    image = image / 255.0\n",
    "    # Reshape the image to match the model's input shape\n",
    "    image = image.reshape(1, 28, 28, 1)\n",
    "    return image\n",
    "\n",
    "# Define a function to make predictions on the preprocessed image\n",
    "def predict_image(image):\n",
    "    # Make a prediction using the model\n",
    "    predictions = model.predict(image)\n",
    "    # Get the predicted digit and its probability\n",
    "    digit = np.argmax(predictions)\n",
    "    probability = predictions[0][digit]\n",
    "    return digit, probability\n",
    "\n",
    "# Define the Gradio interface\n",
    "def sketchpad_digit_recognition(image):\n",
    "    # Preprocess the image\n",
    "    preprocessed_image = preprocess_image(image)\n",
    "    # Make predictions on the preprocessed image\n",
    "    digit, probability = predict_image(preprocessed_image)\n",
    "    # Return the predicted digit and its probability\n",
    "    return digit, probability\n",
    "\n",
    "# Set up the Gradio interface\n",
    "# sketchpad = gr.inputs.Sketchpad()\n",
    "interface = gr.Interface(fn=sketchpad_digit_recognition, inputs=\"sketchpad\",outputs=output_text, title='Sketchpad Digit Recognition')\n",
    "interface.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
